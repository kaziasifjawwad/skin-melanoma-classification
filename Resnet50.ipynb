{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Resnet50.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"IRyFhBF3Zg6Y"},"source":["import os\n","import sys\n","from google.colab import drive"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"17znzgQuSOTo"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"4LSLDwXBZltX","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1615385731344,"user_tz":-360,"elapsed":7330,"user":{"displayName":"hidden tesla","photoUrl":"","userId":"12628822178019786908"}},"outputId":"8bfb7afe-45a9-4f95-d29f-d899823c752c"},"source":["#%tensorflow_version 1.x\n","!pip install keras-vggface\n","!pip install scikit-image\n","!pip install pydot"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: keras-vggface in /usr/local/lib/python3.7/dist-packages (0.6)\n","Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.7/dist-packages (from keras-vggface) (1.4.1)\n","Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.7/dist-packages (from keras-vggface) (1.19.5)\n","Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from keras-vggface) (1.15.0)\n","Requirement already satisfied: keras in /usr/local/lib/python3.7/dist-packages (from keras-vggface) (2.4.3)\n","Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras-vggface) (2.10.0)\n","Requirement already satisfied: pillow in /usr/local/lib/python3.7/dist-packages (from keras-vggface) (7.0.0)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from keras-vggface) (3.13)\n","Requirement already satisfied: scikit-image in /usr/local/lib/python3.7/dist-packages (0.16.2)\n","Requirement already satisfied: imageio>=2.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image) (2.4.1)\n","Requirement already satisfied: PyWavelets>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image) (1.1.1)\n","Requirement already satisfied: pillow>=4.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image) (7.0.0)\n","Requirement already satisfied: matplotlib!=3.0.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image) (3.2.2)\n","Requirement already satisfied: scipy>=0.19.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image) (1.4.1)\n","Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image) (2.5)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from imageio>=2.3.0->scikit-image) (1.19.5)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image) (1.3.1)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image) (0.10.0)\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image) (2.4.7)\n","Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image) (2.8.1)\n","Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.7/dist-packages (from networkx>=2.0->scikit-image) (4.4.2)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from cycler>=0.10->matplotlib!=3.0.0,>=2.0.0->scikit-image) (1.15.0)\n","Requirement already satisfied: pydot in /usr/local/lib/python3.7/dist-packages (1.3.0)\n","Requirement already satisfied: pyparsing>=2.1.4 in /usr/local/lib/python3.7/dist-packages (from pydot) (2.4.7)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"u1rHTXhFZpdl","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1615385735019,"user_tz":-360,"elapsed":3391,"user":{"displayName":"hidden tesla","photoUrl":"","userId":"12628822178019786908"}},"outputId":"23be0bc9-255a-4d3f-f1e4-64eab777e95b"},"source":["!pip install keras_applications"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: keras_applications in /usr/local/lib/python3.7/dist-packages (1.0.8)\n","Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras_applications) (2.10.0)\n","Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.7/dist-packages (from keras_applications) (1.19.5)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from h5py->keras_applications) (1.15.0)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"LNTdowlFZtDt","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1615385732653,"user_tz":-360,"elapsed":1286,"user":{"displayName":"hidden tesla","photoUrl":"","userId":"12628822178019786908"}},"outputId":"5c0ed748-d79f-4fc8-9b6a-777c7ba9354a"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"DRz-0VoOZvxl"},"source":["path = '/content/drive/MyDrive/00 thesis/data set/old/01 unzip file/thesis data kawser/00000000000'"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"o2jVosWsZ-bN"},"source":["filepath = '/content/drive/MyDrive/00 thesis/data set/old/01 unzip file/thesis data kawser/epochs:{epoch:03d}-val_accuracy:{val_accuracy:.3f}.hdf5'"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"PIQFqQg2aANF"},"source":["os.chdir(path)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ocGDp5tAaFs9","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1615385738324,"user_tz":-360,"elapsed":815,"user":{"displayName":"hidden tesla","photoUrl":"","userId":"12628822178019786908"}},"outputId":"83980333-8803-47aa-bdc3-3d72ed90e978"},"source":["ls"],"execution_count":null,"outputs":[{"output_type":"stream","text":["\u001b[0m\u001b[01;34mAK\u001b[0m/  \u001b[01;34mBCC\u001b[0m/  \u001b[01;34mBKL\u001b[0m/  \u001b[01;34mDF\u001b[0m/  \u001b[01;34mMEL\u001b[0m/  \u001b[01;34mNV\u001b[0m/  \u001b[01;34mSCC\u001b[0m/  \u001b[01;34mVASC\u001b[0m/\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"R11PH8FOaK21"},"source":["import matplotlib.pyplot as plt\n","import pandas as pd\n","import numpy as np\n","\n","import tensorflow as tf\n","from tensorflow.keras.layers import *\n","from tensorflow.python.lib.io import file_io\n","\n","%matplotlib inline\n","\n","import keras\n","from keras import backend as K\n","from keras.callbacks import *\n","from keras.models import load_model\n","from keras.preprocessing.image import ImageDataGenerator\n","from keras_vggface.vggface import VGGFace\n","from keras.utils import plot_model\n","from sklearn.metrics import *\n","from keras.engine import Model\n","from keras.layers import Input, Flatten, Dense, Activation, Conv2D, MaxPool2D, BatchNormalization, Dropout, MaxPooling2D\n","import skimage\n","from skimage.transform import rescale, resize\n","\n","import pydot\n","import time"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"XYyaF6WcaNzN","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1615354718536,"user_tz":-360,"elapsed":3079,"user":{"displayName":"hidden tesla","photoUrl":"","userId":"12628822178019786908"}},"outputId":"607ab8e0-bb8d-4646-fd62-4d9c955e97ae"},"source":["print(tf.__version__)\n","print(keras.__version__)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["2.4.1\n","2.4.3\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"A3Qll_d0aP6N"},"source":["EPOCHS = 50\n","BS = 128\n","DROPOUT_RATE = 0.5\n","FROZEN_LAYER_NUM = 170\n","ADAM_LEARNING_RATE = 0.001\n","SGD_LEARNING_RATE = 0.01\n","SGD_DECAY = 0.0001\n","Resize_pixelsize = 250"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"cXjm4FOFaRrt"},"source":["vgg_notop = VGGFace(model='resnet50', include_top=False, input_shape=(Resize_pixelsize, Resize_pixelsize, 3), pooling='avg')\n","last_layer = vgg_notop.get_layer('avg_pool').output\n","x = Flatten(name='flatten')(last_layer)\n","x = Dropout(DROPOUT_RATE)(x)\n","x = Dense(4096, activation='relu', name='fc6')(x)\n","x = Dropout(DROPOUT_RATE)(x)\n","x = Dense(1024, activation='relu', name='fc7')(x)\n","x = Dropout(DROPOUT_RATE)(x)\n","# l=0\n","# for layer in vgg_notop.layers:\n","#     print(layer,\"[\"+str(l)+\"]\")\n","#     l=l+1\n","    \n","batch_norm_indices = [2, 6, 9, 13, 14, 18, 21, 24, 28, 31, 34, 38, 41, 45, 46, 53, 56, 60, 63, 66, 70, 73, 76, 80, 83, 87, 88, 92, 95, 98, 102, 105, 108, 112, 115, 118, 122, 125, 128, 132, 135, 138, 142, 145, 149, 150, 154, 157, 160, 164, 167, 170]\n","for i in range(FROZEN_LAYER_NUM):\n","    if i not in batch_norm_indices:\n","        vgg_notop.layers[i].trainable = False\n","# print('vgg layer 2 is trainable: ' + str(vgg_notop.layers[2].trainable))\n","# print('vgg layer 3 is trainable: ' + str(vgg_notop.layers[3].trainable))\n","\n","out = Dense(8, activation='softmax', name='classifier')(x)\n","\n","model = Model(vgg_notop.input, out)\n","\n","\n","optim = keras.optimizers.Adam(lr=ADAM_LEARNING_RATE, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n","#optim = keras.optimizers.Adam(lr=0.0005, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n","sgd = keras.optimizers.SGD(lr=SGD_LEARNING_RATE, momentum=0.9, decay=SGD_DECAY, nesterov=True)\n","rlrop = keras.callbacks.ReduceLROnPlateau(monitor='val_accuracy',mode='max',factor=0.5, patience=10, min_lr=0.00001, verbose=1)\n","Name = \"tf-SeNet50_cs230_{}\".format(int(time.time()))\n","tensorboard= TensorBoard(log_dir='/content/drive/MyDrive/00 thesis/data set/old/01 unzip file/thesis data kawser/logs/{}'.format(Name))\n","model.compile(optimizer=optim, loss='categorical_crossentropy', metrics=['accuracy'])\n","# plot_model(model, to_file='model2.png', show_shapes=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"SLgrBJoQjm-F"},"source":["early_stop=tf.keras.callbacks.EarlyStopping(patience=5)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"M3Tjjy-9hYVG"},"source":["<h1>Restart<h1>"]},{"cell_type":"code","metadata":{"id":"59W9MaV5hcyT"},"source":["model.load_weights(\"/content/drive/MyDrive/00 thesis/data set/old/01 unzip file/thesis data kawser/epochs:013-val_accuracy:0.605.hdf5\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"lBS_UOp04OXA","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1615385898743,"user_tz":-360,"elapsed":1647,"user":{"displayName":"hidden tesla","photoUrl":"","userId":"12628822178019786908"}},"outputId":"4e5cbbe5-2e07-4a4e-f122-a9d928c7fc23"},"source":["from keras.preprocessing.image import ImageDataGenerator\n","train_data_dir=path  #this is the 000000000 folder\n","\n","img_height=250\n","img_width=250\n","batch_size=16 #previously was 128\n","train_datagen = ImageDataGenerator(rescale=1./255,\n","    shear_range=0.2,\n","    zoom_range=0.2,\n","    horizontal_flip=True,\n","    validation_split=0.2) # set validation split\n","\n","train_generator = train_datagen.flow_from_directory(\n","    train_data_dir,\n","    target_size=(img_height, img_width),\n","    batch_size=batch_size,\n","    class_mode= 'categorical',\n","    subset='training') # set as training data\n","\n","validation_generator = train_datagen.flow_from_directory(\n","    train_data_dir, # same directory as training data\n","    target_size=(img_height, img_width),\n","    batch_size=batch_size,\n","    class_mode='categorical',\n","    subset='validation') # set as validation data\n","\n","# model.fit_generator(\n","#     train_generator,\n","#     steps_per_epoch = train_generator.samples // batch_size,\n","#     validation_data = validation_generator, \n","#     validation_steps = validation_generator.samples // batch_size,\n","#     epochs = nb_epochs)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Found 20269 images belonging to 8 classes.\n","Found 5062 images belonging to 8 classes.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"HFgxRJQMcc9d"},"source":["#train_generator  = get_datagen('/content/drive/My Drive/Facial_Expression_Recognition/train', True)\n","#dev_generator    = get_datagen('/content/dev')\n","#dev_generator  = get_datagen('/content/drive/My Drive/Facial_Expression_Recognition/test')\n","#train_generator  = get_datagen('/content/drive/My Drive/Facial_Expression_Recognition_TTV/train', True)\n","#dev_generator    = get_datagen('/content/drive/My Drive/Facial_Expression_Recognition_TTV/val')\n","#test_generator  = get_datagen('/content/drive/My Drive/Facial_Expression_Recognition_TTV/test')\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0NpT_BfJcfp1"},"source":["checkpoint = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"qoZ1xDcqEo1x"},"source":["#model.load_weights('/content/drive/My Drive/Facial_Expression_Recognition_TTV/weight/epochs:071-val_accuracy:0.712.hdf5')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"rYVp9uygC1Iv"},"source":["model.summary()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6tktPinnchmF","colab":{"base_uri":"https://localhost:8080/"},"outputId":"1efc5a6f-d32a-4481-9c4a-31100931f561"},"source":["#history = model.fit(\n","#    x = train_generator,\n","#    validation_data = dev_generator, \n","    #steps_per_epoch=28709// BS,\n","    #validation_steps=3509 // BS,\n","#    shuffle=True,\n","#    epochs=20,\n","#    callbacks=[rlrop, tensorboard, checkpoint]\n","#)\n","print(train_generator)\n","\n","history = model.fit(\n","    x = train_generator,\n","    validation_data=validation_generator, \n","    steps_per_epoch=20269 // BS,\n","    validation_steps=5062 // BS,\n","    shuffle=True,\n","    epochs=50,\n","    callbacks=[rlrop, tensorboard, checkpoint]\n",")\n","\n","\n","epoch_str = '-EPOCHS_' + str(EPOCHS)\n","test_acc = 'test_acc_%.3f' % results_test[1]\n","#model.save('/content/drive/My Drive/Facial_Expression_Recognition/weight/' + 'SENET50' + epoch_str + test_acc + '.h5')\n","# list all data in history\n","print(history.history.keys())\n","# summarize history for accuracy\n","plt.plot(history.history['accuracy'])\n","plt.plot(history.history['val_accuracy'])\n","plt.title('model accuracy')\n","plt.ylabel('accuracy')\n","plt.xlabel('epoch')\n","plt.legend(['train', 'dev'], loc='upper left')\n","plt.show()\n","# summarize history for loss\n","plt.plot(history.history['loss'])\n","plt.plot(history.history['val_loss'])\n","plt.title('model loss')\n","plt.ylabel('loss')\n","plt.xlabel('epoch')\n","plt.legend(['train', 'dev'], loc='upper left')\n","plt.show()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["<tensorflow.python.keras.preprocessing.image.DirectoryIterator object at 0x7fab962f0810>\n","Epoch 1/50\n","  3/158 [..............................] - ETA: 18:21 - loss: 12.8022 - accuracy: 0.2917"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"cp2J_V9tebbe"},"source":["print(history.history.keys())\n","# summarize history for accuracy\n","plt.plot(history.history['accuracy'])\n","plt.plot(history.history['val_accuracy'])\n","plt.title('model accuracy')\n","plt.ylabel('accuracy')\n","plt.xlabel('epoch')\n","plt.legend(['train', 'dev'], loc='upper left')\n","plt.show()\n","# summarize history for loss\n","plt.plot(history.history['loss'])\n","plt.plot(history.history['val_loss'])\n","plt.title('model loss')\n","plt.ylabel('loss')\n","plt.xlabel('epoch')\n","plt.legend(['train', 'dev'], loc='upper left')\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5cN-_0xihIIM"},"source":["print('\\n# Evaluate on dev data')\n","results_dev = model.evaluate_generator(dev_generator, 3509 // BS)\n","print('dev loss, dev acc:', results_dev)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"WpSzg9l8fXvJ"},"source":["print('\\n# Evaluate on test data')\n","results_test = model.evaluate_generator(test_generator, 3509 // BS)\n","print('test loss, test acc:', results_test)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"9WwFIhRzfffo"},"source":["# list all data in history\n","print(history.history.keys())\n","# summarize history for accuracy\n","plt.plot(history.history['acc'])\n","plt.plot(history.history['val_acc'])\n","plt.title('model accuracy')\n","plt.ylabel('accuracy')\n","plt.xlabel('epoch')\n","plt.legend(['train', 'dev'], loc='upper left')\n","plt.show()\n","# summarize history for loss\n","plt.plot(history.history['loss'])\n","plt.plot(history.history['val_loss'])\n","plt.title('model loss')\n","plt.ylabel('loss')\n","plt.xlabel('epoch')\n","plt.legend(['train', 'dev'], loc='upper left')\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"KZXsdFd6rF0c"},"source":[""],"execution_count":null,"outputs":[]}]}